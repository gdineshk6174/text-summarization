{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "text summarization-01.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "K3Ldbb5yhD2K",
        "colab_type": "code",
        "colab": {},
        "outputId": "7bc23ec6-5003-4512-9cf1-5fecb29af9d8"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/kaggle/input/amazon-fine-food-reviews/hashes.txt\n",
            "/kaggle/input/amazon-fine-food-reviews/database.sqlite\n",
            "/kaggle/input/amazon-fine-food-reviews/Reviews.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "jwFd16fhhD2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dependencies\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "aEJCvwlmhD2Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('../input/amazon-fine-food-reviews/Reviews.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "i0m9WsKThD2e",
        "colab_type": "code",
        "colab": {},
        "outputId": "102f9cfb-bb31-4114-c006-824a21443895"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id   ProductId          UserId                      ProfileName  \\\n",
              "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
              "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
              "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
              "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
              "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
              "\n",
              "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
              "0                     1                       1      5  1303862400   \n",
              "1                     0                       0      1  1346976000   \n",
              "2                     1                       1      4  1219017600   \n",
              "3                     3                       3      2  1307923200   \n",
              "4                     0                       0      5  1350777600   \n",
              "\n",
              "                 Summary                                               Text  \n",
              "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
              "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
              "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
              "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
              "4            Great taffy  Great taffy at a great price.  There was a wid...  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "I0Phz6kZhD2l",
        "colab_type": "code",
        "colab": {},
        "outputId": "8b07f2c2-431f-48f4-beab-5a716294f97c"
      },
      "source": [
        "train = train[['Summary', 'Text']]\n",
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  Summary                                               Text\n",
              "0   Good Quality Dog Food  I have bought several of the Vitality canned d...\n",
              "1       Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...\n",
              "3          Cough Medicine  If you are looking for the secret ingredient i...\n",
              "4             Great taffy  Great taffy at a great price.  There was a wid...\n",
              "7  Wonderful, tasty taffy  This taffy is so good.  It is very soft and ch..."
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>Wonderful, tasty taffy</td>\n",
              "      <td>This taffy is so good.  It is very soft and ch...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "C2gKpRsDhD2w",
        "colab_type": "code",
        "colab": {},
        "outputId": "1bf37ede-2790-4dc9-8995-8e7a512b0a1a"
      },
      "source": [
        "train['text_len'] = train['Text'].str.count(' ')\n",
        "train['text_len'].describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    568454.000000\n",
              "mean         81.005522\n",
              "std          80.807102\n",
              "min           2.000000\n",
              "25%          33.000000\n",
              "50%          57.000000\n",
              "75%          99.000000\n",
              "max        3525.000000\n",
              "Name: text_len, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jV3XU8YDhD27",
        "colab_type": "text"
      },
      "source": [
        "we have text with a min of 2 words to max of 3525 words in text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mIbeY1-9hD2-",
        "colab_type": "code",
        "colab": {},
        "outputId": "4fa81f51-d521-43c4-d7c1-45df8d62ddae"
      },
      "source": [
        "train['summary_len'] = train['Summary'].str.count(' ')\n",
        "train['summary_len'].describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    568427.000000\n",
              "mean          3.128462\n",
              "std           2.619420\n",
              "min           0.000000\n",
              "25%           1.000000\n",
              "50%           3.000000\n",
              "75%           4.000000\n",
              "max          41.000000\n",
              "Name: summary_len, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1UYJpxXhD3O",
        "colab_type": "text"
      },
      "source": [
        "here we have summaries rangeing from no words to max of 41 words also 75% of the summaries are below 4 words.\n",
        "also we can say that the summaries for most of the text are small and quick summary\\n\n",
        "we can also see that mean of text sentences is 81 words and mean of summaries is 3 words .so very large texts have short summaries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62gb6NI6hD3Q",
        "colab_type": "raw"
      },
      "source": [
        "# now let us work on short summaries and short texts so that we can build a simpler model and quick on computation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ReXnRAxRhD3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train.loc[train['summary_len']< 10]\n",
        "train = train.loc[train['text_len']< 50]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "TsYXTDQThD3Z",
        "colab_type": "code",
        "colab": {},
        "outputId": "0afa557f-7b5c-4b42-cd16-2a1eef5aa35b"
      },
      "source": [
        "print (train.shape)\n",
        "print (train.head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(244511, 4)\n",
            "                  Summary                                               Text  \\\n",
            "0   Good Quality Dog Food  I have bought several of the Vitality canned d...   \n",
            "1       Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...   \n",
            "3          Cough Medicine  If you are looking for the secret ingredient i...   \n",
            "4             Great taffy  Great taffy at a great price.  There was a wid...   \n",
            "7  Wonderful, tasty taffy  This taffy is so good.  It is very soft and ch...   \n",
            "\n",
            "   text_len  summary_len  \n",
            "0        48          3.0  \n",
            "1        30          2.0  \n",
            "3        42          1.0  \n",
            "4        29          1.0  \n",
            "7        27          2.0  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JjGuxpT7hD4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# text preprocessing - lower case letter and removing punctuation\n",
        "# train['Text']\n",
        "train['text_lower'] = train['Text'].str.lower()\n",
        "train['text_no_punc'] = train['text_lower'].str.replace('[^\\w\\s]','')\n",
        "#train['Summary']\n",
        "train['summary_lower'] = train['Summary'].str.lower()\n",
        "train['summary_no_punc'] = '_start_'+ ' ' +train['summary_lower'].str.replace('[^\\w\\s]','')+ ' ' +'_end_'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zSq8lsKRhD4H",
        "colab_type": "code",
        "colab": {},
        "outputId": "73a87c3c-c7ff-4ec1-beb0-6321ae08f803"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  Summary                                               Text  \\\n",
              "0   Good Quality Dog Food  I have bought several of the Vitality canned d...   \n",
              "1       Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...   \n",
              "3          Cough Medicine  If you are looking for the secret ingredient i...   \n",
              "4             Great taffy  Great taffy at a great price.  There was a wid...   \n",
              "7  Wonderful, tasty taffy  This taffy is so good.  It is very soft and ch...   \n",
              "\n",
              "   text_len  summary_len                                         text_lower  \\\n",
              "0        48          3.0  i have bought several of the vitality canned d...   \n",
              "1        30          2.0  product arrived labeled as jumbo salted peanut...   \n",
              "3        42          1.0  if you are looking for the secret ingredient i...   \n",
              "4        29          1.0  great taffy at a great price.  there was a wid...   \n",
              "7        27          2.0  this taffy is so good.  it is very soft and ch...   \n",
              "\n",
              "                                        text_no_punc           summary_lower  \\\n",
              "0  i have bought several of the vitality canned d...   good quality dog food   \n",
              "1  product arrived labeled as jumbo salted peanut...       not as advertised   \n",
              "3  if you are looking for the secret ingredient i...          cough medicine   \n",
              "4  great taffy at a great price  there was a wide...             great taffy   \n",
              "7  this taffy is so good  it is very soft and che...  wonderful, tasty taffy   \n",
              "\n",
              "                       summary_no_punc  \n",
              "0  _start_ good quality dog food _end_  \n",
              "1      _start_ not as advertised _end_  \n",
              "3         _start_ cough medicine _end_  \n",
              "4            _start_ great taffy _end_  \n",
              "7  _start_ wonderful tasty taffy _end_  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "      <th>text_len</th>\n",
              "      <th>summary_len</th>\n",
              "      <th>text_lower</th>\n",
              "      <th>text_no_punc</th>\n",
              "      <th>summary_lower</th>\n",
              "      <th>summary_no_punc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "      <td>48</td>\n",
              "      <td>3.0</td>\n",
              "      <td>i have bought several of the vitality canned d...</td>\n",
              "      <td>i have bought several of the vitality canned d...</td>\n",
              "      <td>good quality dog food</td>\n",
              "      <td>_start_ good quality dog food _end_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "      <td>30</td>\n",
              "      <td>2.0</td>\n",
              "      <td>product arrived labeled as jumbo salted peanut...</td>\n",
              "      <td>product arrived labeled as jumbo salted peanut...</td>\n",
              "      <td>not as advertised</td>\n",
              "      <td>_start_ not as advertised _end_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "      <td>42</td>\n",
              "      <td>1.0</td>\n",
              "      <td>if you are looking for the secret ingredient i...</td>\n",
              "      <td>if you are looking for the secret ingredient i...</td>\n",
              "      <td>cough medicine</td>\n",
              "      <td>_start_ cough medicine _end_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "      <td>29</td>\n",
              "      <td>1.0</td>\n",
              "      <td>great taffy at a great price.  there was a wid...</td>\n",
              "      <td>great taffy at a great price  there was a wide...</td>\n",
              "      <td>great taffy</td>\n",
              "      <td>_start_ great taffy _end_</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>Wonderful, tasty taffy</td>\n",
              "      <td>This taffy is so good.  It is very soft and ch...</td>\n",
              "      <td>27</td>\n",
              "      <td>2.0</td>\n",
              "      <td>this taffy is so good.  it is very soft and ch...</td>\n",
              "      <td>this taffy is so good  it is very soft and che...</td>\n",
              "      <td>wonderful, tasty taffy</td>\n",
              "      <td>_start_ wonderful tasty taffy _end_</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4U_YxztkhD4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features1 = 5000\n",
        "maxlen1 = 50\n",
        "\n",
        "max_features2 = 5000\n",
        "maxlen2 = 10\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ohAK1hexhD4Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# basic text preprocessing [ words > tokenizer > fit-on-text > text_seq > pad_seq]\n",
        "tok1 = tf.keras.preprocessing.text.Tokenizer(num_words = max_features1)\n",
        "tok1.fit_on_texts(list(train['text_no_punc'].astype(str)))\n",
        "tf_train_text = tok1.texts_to_sequences(list(train['text_no_punc'].astype(str)))\n",
        "tf_train_text = tf.keras.preprocessing.sequence.pad_sequences(tf_train_text, maxlen = maxlen1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "maY8hPL8hD4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# basic text preprocessing [ words > tokenizer > fit-on-text > text_seq > pad_seq]\n",
        "tok2 = tf.keras.preprocessing.text.Tokenizer(num_words = max_features2, filters = '*')\n",
        "tok2.fit_on_texts(list(train['summary_no_punc'].astype(str)))\n",
        "tf_train_summary = tok2.texts_to_sequences(list(train['summary_no_punc'].astype(str)))\n",
        "tf_train_summary= tf.keras.preprocessing.sequence.pad_sequences(tf_train_summary, maxlen = maxlen2, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "QcmgjlshhD4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model architecture\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fB7Hw6sahD4g",
        "colab_type": "code",
        "colab": {},
        "outputId": "e8dc35ca-1ca4-46b6-fbeb-bc944b4adc73"
      },
      "source": [
        "print(tf_train_summary[:2,:-1])\n",
        "print(tf_train_summary[:2,1:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  1   4  68  28  38   2   0   0   0]\n",
            " [  1  13  45 505   2   0   0   0   0]]\n",
            "[[  4  68  28  38   2   0   0   0   0]\n",
            " [ 13  45 505   2   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9Ozy1SWJhD4k",
        "colab_type": "code",
        "colab": {},
        "outputId": "063edea2-d82f-4977-f84f-15497621ec21"
      },
      "source": [
        "vectorized_summary = tf_train_summary\n",
        "# for decoder input we dont need last word as that is only for prediction\n",
        "decoder_input_data = vectorized_summary[:,:-1]\n",
        "# for decoder target is 1 timestep ahead from decoderinput data\n",
        "decoder_target_data = vectorized_summary[:,1:]\n",
        "\n",
        "print (f'shape of decoder input :{decoder_input_data.shape}')\n",
        "print (f'shape of decoder target :{decoder_target_data.shape}')\n",
        "\n",
        "vectorized_text = tf_train_text\n",
        "\n",
        "encoder_input_data = vectorized_text\n",
        "doc_length = encoder_input_data.shape[1]\n",
        "print (f'shape of encoder input :{encoder_input_data.shape}')\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of decoder input :(244511, 9)\n",
            "shape of decoder target :(244511, 9)\n",
            "shape of encoder input :(244511, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "us_-j82vhD4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size_encoder = len(tok1.word_index)+1\n",
        "vocab_size_decoder = len(tok2.word_index)+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lRVQA1LRhD4u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# defining model parameters\n",
        "latent_dim = 50\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "i_TxTA4JhD4z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####################\n",
        "####encoder model###\n",
        "####################\n",
        "encoder_inputs = tf.keras.Input(shape = (doc_length,), name = 'Encoder-Input')\n",
        "# embedding\n",
        "x=tf.keras.layers.Embedding(vocab_size_encoder,latent_dim,name='Body-word-embedding',mask_zero=False)(encoder_inputs)\n",
        "# bacth normalization\n",
        "x = tf.keras.layers.BatchNormalization(name = 'Encoder-batchnorm-1')(x)\n",
        "# in encoder we dont need encoder output just hidden state\n",
        "_, state_h = tf.keras.layers.GRU(latent_dim, return_state = True , name = 'Encoder-last-GRU')(x)\n",
        "# encapsulating the encoder as a seperate so we can encode without decoding if we want to\n",
        "encoder_model = tf.keras.Model(inputs = encoder_inputs , outputs = state_h, name = 'Encoder-model')\n",
        "\n",
        "seq2seq_encoder_out = encoder_model(encoder_inputs)\n",
        "\n",
        "####################\n",
        "####decoder model###\n",
        "####################\n",
        "decoder_inputs = tf.keras.Input(shape = (None,) , name = 'Decoder-input')\n",
        "# embedding\n",
        "dec_emb=tf.keras.layers.Embedding(vocab_size_decoder,latent_dim,name='decoder-word-embedding',mask_zero=False)(decoder_inputs)\n",
        "#batch normalization\n",
        "dec_bn = tf.keras.layers.BatchNormalization(name = 'Decoder-batchnorm-1')(dec_emb)\n",
        "\n",
        "dec_gru =  tf.keras.layers.GRU(latent_dim, return_state = True, return_sequences = True, name = 'Decoder-GRU')\n",
        "dec_gru_output, _ = dec_gru(dec_bn, initial_state = seq2seq_encoder_out)\n",
        "# batchnormalization\n",
        "dec_bn_2 = tf.keras.layers.BatchNormalization(name = 'Decoder-batchnorm-2')(dec_gru_output)\n",
        "\n",
        "# dense layers\n",
        "dec_dense = tf.keras.layers.Dense(vocab_size_decoder, activation = 'softmax',name = 'Final-output-dense')\n",
        "dec_outputs = dec_dense(dec_bn_2)\n",
        "\n",
        "####################\n",
        "####seq2seq model###\n",
        "####################\n",
        "seq2seq_model= tf.keras.Model([encoder_inputs, decoder_inputs], dec_outputs)\n",
        "\n",
        "seq2seq_model.compile(optimizer = tf.keras.optimizers.Nadam(lr = 0.001), loss = 'sparse_categorical_crossentropy')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "emh3mbhEhD46",
        "colab_type": "code",
        "colab": {},
        "outputId": "5d7f06f6-59eb-4deb-b9d5-1d116a5a3413"
      },
      "source": [
        "# summary of the model\n",
        "seq2seq_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Decoder-input (InputLayer)      [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "decoder-word-embedding (Embeddi (None, None, 50)     1148450     Decoder-input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Input (InputLayer)      [(None, 50)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Decoder-batchnorm-1 (BatchNorma (None, None, 50)     200         decoder-word-embedding[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-model (Model)           (None, 50)           3886650     Encoder-Input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Decoder-GRU (GRU)               [(None, None, 50), ( 15150       Decoder-batchnorm-1[0][0]        \n",
            "                                                                 Encoder-model[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Decoder-batchnorm-2 (BatchNorma (None, None, 50)     200         Decoder-GRU[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "Final-output-dense (Dense)      (None, None, 22969)  1171419     Decoder-batchnorm-2[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 6,222,069\n",
            "Trainable params: 6,221,769\n",
            "Non-trainable params: 300\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qHM9zJ7EhD5B",
        "colab_type": "code",
        "colab": {},
        "outputId": "6db30ec0-7bdf-4b3e-feb4-3f406ab0639d"
      },
      "source": [
        "#training the model\n",
        "batch_size = 64\n",
        "epochs = 5\n",
        "history = seq2seq_model.fit([encoder_input_data,decoder_input_data], np.expand_dims(decoder_target_data, -1)\n",
        "                           ,batch_size = batch_size\n",
        "                           ,epochs = epochs\n",
        "                           ,validation_split = 0.1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 220059 samples, validate on 24452 samples\n",
            "Epoch 1/5\n",
            "220059/220059 [==============================] - 320s 1ms/sample - loss: 2.0097 - val_loss: 1.5817\n",
            "Epoch 2/5\n",
            "220059/220059 [==============================] - 319s 1ms/sample - loss: 1.4903 - val_loss: 1.4732\n",
            "Epoch 3/5\n",
            "220059/220059 [==============================] - 317s 1ms/sample - loss: 1.3772 - val_loss: 1.4304\n",
            "Epoch 4/5\n",
            "220059/220059 [==============================] - 317s 1ms/sample - loss: 1.3140 - val_loss: 1.4103\n",
            "Epoch 5/5\n",
            "220059/220059 [==============================] - 319s 1ms/sample - loss: 1.2725 - val_loss: 1.3996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Lt151LXphD5G",
        "colab_type": "code",
        "colab": {},
        "outputId": "e70f154d-4791-442e-abf8-cbc0d2bf116e"
      },
      "source": [
        "train['text_no_punc'].tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "568448    my only complaint is that theres so much of it...\n",
              "568449    great for sesame chickenthis is a good if not ...\n",
              "568450    im disappointed with the flavor the chocolate ...\n",
              "568452    these are the best treats for training and rew...\n",
              "568453    i am very satisfied product is as advertised i...\n",
              "Name: text_no_punc, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qSAxUxkJhD5K",
        "colab_type": "code",
        "colab": {},
        "outputId": "993c05cb-d616-4d03-d0da-53b99ec787e3"
      },
      "source": [
        "train['text_no_punc'][568452]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'these are the best treats for training and rewarding your dog for being good while grooming  lower in calories and loved by all the doggies  sweet potatoes seem to be their favorite wet noses treat'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "67_JJG-XhD5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_text = ['these are the best treats for training and rewarding your dog for being good while grooming  lower in calories and loved by all the doggies  sweet potatoes seem to be their favorite wet noses treat']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2ob3t3FEhD5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encoder's features for the test_text\n",
        "tok1.fit_on_texts(test_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "nI22kOwthD5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_tokenized = tok1.texts_to_sequences(test_text)\n",
        "raw_tokenized = tf.keras.preprocessing.sequence.pad_sequences(raw_tokenized,maxlen = maxlen1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "x34Kv1x-hD5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encoded state of the new sentence\n",
        "body_encoding = encoder_model.predict(raw_tokenized)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0vm6mhVohD5e",
        "colab_type": "code",
        "colab": {},
        "outputId": "9a88b2f9-205a-42ac-9b32-2d740874f003"
      },
      "source": [
        "body_encoding"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.88661003, -0.29484174,  0.8297895 ,  0.7951673 ,  0.26189852,\n",
              "        -0.2639114 , -0.65622485,  0.5583709 ,  0.00414825,  0.15360205,\n",
              "        -0.39446795,  0.3432643 , -0.4579382 ,  0.69474727,  0.23721723,\n",
              "        -0.61368674,  0.17786449,  0.55498576,  0.06720206,  0.5624686 ,\n",
              "         0.6184739 ,  0.6955943 , -0.51201224,  0.945051  , -0.63321745,\n",
              "         0.8300117 ,  0.55848235,  0.9674921 ,  0.3379451 ,  0.26968428,\n",
              "        -0.71685606, -0.8896725 ,  0.45976993,  0.0992775 , -0.16117108,\n",
              "         0.8465392 , -0.73164713, -0.29591882,  0.20760846,  0.06894144,\n",
              "        -0.2985663 ,  0.9341779 ,  0.8815483 ,  0.27380165,  0.48696768,\n",
              "         0.20732337,  0.10657895,  0.17559054, -0.52167165, -0.20925842]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "WwCxVjHGhD5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "latent_dim = seq2seq_model.get_layer('decoder-word-embedding').output_shape[-1]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "TwOfczzlhD5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reconstruct the input into the decoder\n",
        "decoder_inputs = seq2seq_model.get_layer('Decoder-input').input\n",
        "dec_emb = seq2seq_model.get_layer('decoder-word-embedding')(decoder_inputs)\n",
        "dec_bn = seq2seq_model.get_layer('Decoder-batchnorm-1')(dec_emb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9bQBAPa3hD5u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gru_inference_state_input = tf.keras.Input(shape = (latent_dim,),name = 'hidden_state_input')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "sg6VQrTPhD5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gru_out, gru_state_out = seq2seq_model.get_layer('Decoder-GRU')([dec_bn, gru_inference_state_input])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mBfxseRihD52",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# recontruct dense layers\n",
        "dec_bn2 = seq2seq_model.get_layer('Decoder-batchnorm-2')(gru_out)\n",
        "dense_out = seq2seq_model.get_layer('Final-output-dense')(dec_bn2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "mtZt9XEKhD57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_model = tf.keras.Model([decoder_inputs, gru_inference_state_input],[dense_out,gru_state_out])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UO0iCG4zhD5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_body_encoding = body_encoding\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6kwkmPAyhD6B",
        "colab_type": "code",
        "colab": {},
        "outputId": "fbafa55c-d44b-49fe-d40e-606088e39a9b"
      },
      "source": [
        "#print (np.array(tok2.word_index['_start_']))\n",
        "state_value = np.array(tok2.word_index['_start_']).reshape(1,1)\n",
        "state_value"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Tqf0apb3hD6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoded_sentence = []\n",
        "stop_condition = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "dMtiE3AVhD6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_inv = dict((v, k) for k,v in tok2.word_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "eqidpDWkhD6U",
        "colab_type": "code",
        "colab": {},
        "outputId": "5d1d21d9-e986-488b-d1a0-bb379c8450be"
      },
      "source": [
        "print ('sample text is %s'%test_text)\n",
        "#print ('summary of test_text is',decoded_sentence)\n",
        "while not stop_condition:\n",
        "    preds, st = decoder_model.predict([state_value,body_encoding])\n",
        " \n",
        "    pred_idx = np.argmax(preds[:,:, 2:])+2\n",
        "    pred_word_str = vocab_inv[pred_idx]\n",
        "    #print (pred_word_str)\n",
        "    if pred_word_str == '_end_' or len(decoded_sentence) >= maxlen2:\n",
        "        stop_condition = True\n",
        "        break\n",
        "        \n",
        "    decoded_sentence.append(pred_word_str)\n",
        "    \n",
        "    body_encoding = st\n",
        "    state_value = np.array(pred_idx).reshape(1,1)\n",
        "    \n",
        "summary = ' '.join(decoded_sentence)\n",
        "print ('---------------------')\n",
        "print ('summary of sample text is: \"%s\"'%summary)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample text is ['these are the best treats for training and rewarding your dog for being good while grooming  lower in calories and loved by all the doggies  sweet potatoes seem to be their favorite wet noses treat']\n",
            "---------------------\n",
            "summary of sample text is: \"great treats\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Scqolq7LhD6a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}